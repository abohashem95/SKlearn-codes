{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metrics module.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sJb5W4rEhu29"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9S91uutEMArO+dplLeN87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abohashem95/SKlearn-codes/blob/main/Metrics_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkifMrzxiJIj"
      },
      "source": [
        "# Metrics Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEDpsm-xiCSS"
      },
      "source": [
        " هي بالغة الأهمية في عمل حساب لكمية الأخطاء اثناء الاختبار , وتنقسم إلي نوعين , نوع للتوقع , ونوع للتصنيف  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJb5W4rEhu29"
      },
      "source": [
        "## Regrassion tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8bTYd5N0w4B"
      },
      "source": [
        "### mean absolute error \n",
        "\n",
        "equation:\n",
        "1/n * sum(y-y`)\n",
        "\n",
        "where\n",
        "y: y true\n",
        "\n",
        "y`: y predict\n",
        "\n",
        "n: number of samples\n",
        "\n",
        "code:\n",
        "\n",
        " **Import Libraries**\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "\n",
        "**----------------------------------------------------**\n",
        "\n",
        "**Calculating Mean Absolute Error**\n",
        "\n",
        "MAEValue = mean_absolute_error(y_test, y_pred, \n",
        "multioutput='uniform_average') \n",
        "   **it can be raw_values**\n",
        "\n",
        "print('Mean Absolute Error Value is : ', MAEValue)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5_Zf8xhh6GH",
        "outputId": "ff06b651-6a82-4632-8e82-dbd78cd7f800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example 1 real numbers in list\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "y_true = [3, -0.5, 2, 7]\n",
        "y_pred = [2.5, 0.0, 2, 8]\n",
        "mean_absolute_error(y_true, y_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWJu1LshO_Zt",
        "outputId": "eef3d76c-bea6-448e-9e2d-cefd5f13b88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# example 2  matrices \n",
        "\n",
        "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
        "y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
        "# هنا ياتي بالمتوسط لهم كلهم\n",
        "print(mean_absolute_error(y_true, y_pred)) # 0.75\n",
        "print(mean_absolute_error(y_true, y_pred, multioutput='uniform_average')) # 0.75\n",
        "# و هنا لكل صف علي حدة \n",
        "print(mean_absolute_error(y_true, y_pred, multioutput='raw_values')) # array([0.5, 1. ])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.75\n",
            "0.75\n",
            "[0.5 1. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFrCnvTFRJrI"
      },
      "source": [
        "### mean squared error \n",
        "\n",
        "equation:\n",
        "1/n * sum(y-y`)^2\n",
        "\n",
        "where\n",
        "y: y true\n",
        "\n",
        "y`: y predict\n",
        "\n",
        "n: number of samples\n",
        "\n",
        "code:\n",
        "\n",
        " **Import Libraries**\n",
        "\n",
        "from sklearn.metrics import mean_squared_error  \n",
        "\n",
        "**----------------------------------------------------**\n",
        "\n",
        "**Calculating Mean squared Error**\n",
        "\n",
        "MSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') \n",
        "   **it can be raw_values**\n",
        "\n",
        "print('Mean Squared Error Value is : ', MSEValue)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH5SQaCuPjDE",
        "outputId": "a02184b7-0c68-4aaa-9b5d-6f74e6bd80c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example 1 \n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "y_true = [3, -0.5, 2, 7]\n",
        "y_pred = [2.5, 0.0, 2, 8]\n",
        "mean_squared_error(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpNlKqJ2Qsno",
        "outputId": "f7cfaf5f-160f-4649-b1bc-481bb0317db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# example 2 \n",
        "\n",
        "y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
        "y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
        "\n",
        "# هنا ياتي بالمتوسط لهم كلهم\n",
        "\n",
        "print(mean_squared_error(y_true, y_pred))\n",
        "print(mean_squared_error(y_true, y_pred, multioutput='uniform_average')) \n",
        "# و هنا لكل صف علي حدة \n",
        "\n",
        "print(mean_squared_error(y_true, y_pred, multioutput='raw_values'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "[0.41666667 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExbhrF0rRmDQ"
      },
      "source": [
        "### Median Absolute Error\n",
        "\n",
        "نفس فكرة mean  لكنه يقوم برص قيم الاخطاء و اختيار القيمة الـmedian\n",
        "\n",
        "\n",
        "\n",
        "code:\n",
        "\n",
        " **Import Libraries**\n",
        "\n",
        "from sklearn.metrics import median_absolute_error  \n",
        "\n",
        "**----------------------------------------------------**\n",
        "\n",
        "**Calculating Median Absolute Error**\n",
        "\n",
        "MdSEValue = median_absolute_error(y_test, y_pred) \n",
        "   \n",
        "print('Median Squared Error Value is : ', MdSEValue )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wATYp9Z0Q0Ti",
        "outputId": "7f766edf-331d-40a4-e5ce-ea08a044e9a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example 1\n",
        "\n",
        "from sklearn.metrics import median_absolute_error\n",
        "y_true = [3, -0.5, 2, 7]\n",
        "y_pred = [2.5, 0.0, 2, 8]\n",
        "median_absolute_error(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDwekVEDSu6F"
      },
      "source": [
        "## classification tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlOML235S9XN"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "\n",
        "\n",
        "   ==============\n",
        "\n",
        "      TP     FP\n",
        "\n",
        "      FN     TN\n",
        "   =============="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-LRPW4XV3Mr",
        "outputId": "251da3d3-70b8-4658-a254-3d90ad6a9a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = ['a','a','b','b','a','b','a','a','a','a']\n",
        "y_true  = ['a','b','b','a','b','a','a','b','a','b']\n",
        "confusion_matrix(y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#                pred a      pred b\n",
        "#   actual a       3           2\n",
        "\n",
        "#   actual b       4           1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 2],\n",
              "       [4, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCMGFZyPXwdz",
        "outputId": "b535458f-dc0c-406f-975a-39b297ea3d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#example 2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred =  ['a','b','c','a','b','c','a','b','c','a']\n",
        "y_true =  ['a','a','b','b','a','b','c','c','b','b']\n",
        "confusion_matrix(y_true, y_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 0],\n",
              "       [2, 0, 3],\n",
              "       [1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JztBTbSEDhit",
        "outputId": "8ffa2b36-ff3a-41b4-fc1c-196acff3c8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# example 3 \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = [5,8,9,9,8,5,5,9,8,5,9,8]\n",
        "y_true =  [9,9,8,8,5,5,9,5,8,9,8,5]\n",
        "confusion_matrix(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 1],\n",
              "       [0, 1, 3],\n",
              "       [3, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj0259NjEjAn"
      },
      "source": [
        "### Accuracy Score\n",
        "\n",
        "((TP + TN) / float(TP + TN + FP + FN))\n",
        "\n",
        "**Import Libraries**\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "**----------------------------------------------------**\n",
        "\n",
        "**Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))**\n",
        "\n",
        "AccScore = accuracy_score(y_test, y_pred, normalize=False)\n",
        "\n",
        "print('Accuracy Score is : ', AccScore)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj3-TgM-EeVJ",
        "outputId": "2a388903-337d-4d62-e6d1-8c4cef44fd20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# example 1\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = [0, 2, 1, 3,5,3]\n",
        "y_true = [0, 1, 2, 3,5,3]\n",
        "print(accuracy_score(y_true, y_pred)) # fraction of all Trues over everything\n",
        "print(accuracy_score(y_true, y_pred, normalize=False)) #number of all Trues"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666666\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp3J3hwFIemJ"
      },
      "source": [
        "### Recall Score (Sensitivity)\n",
        "\n",
        "(TP / float(TP + FN))   \n",
        "\n",
        "\n",
        "recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZotWM7YFI0_",
        "outputId": "0ca818d3-c9f8-4405-939a-ae232c1cadcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "y_pred =  ['a','b','c','a','b','c','a','b','c','a']\n",
        "y_true =   ['a','a','b','b','a','b','c','c','b','b']\n",
        "recall_score(y_true, y_pred, average=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.33333333, 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUAepRUFJIxH"
      },
      "source": [
        "### Precision Score (Specificity)\n",
        "\n",
        "(TP / float(TP + FP)) \n",
        "\n",
        "precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)\n",
        "\n",
        "it can be : binary,macro,weighted,samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7McaVCmyIyQS",
        "outputId": "98033cca-7978-451d-b704-b21f17415661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example \n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        " \n",
        "y_pred =  ['a','b','c','a','b','c','a','b','c','a']\n",
        "y_true =   ['a','a','b','b','a','b','c','c','b','b']\n",
        "\n",
        "precision_score(y_true, y_pred, average=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.  , 0.  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzcvPaKmJyTO"
      },
      "source": [
        "### F1 Score\n",
        "\n",
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
        "\n",
        "it can be : binary,macro,weighted,samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C0TouZXJn8X",
        "outputId": "359173b1-6f49-41a2-df29-99477af1abd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example \n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "y_pred = [0, 2, 1, 0, 0, 1]\n",
        "y_true = [0, 1, 2, 0, 1, 2]\n",
        "f1_score(y_true, y_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-R-q_7zKRNg"
      },
      "source": [
        "### Precision Recall Fscore Support\n",
        "\n",
        "metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average= None, warn_for = ('precision’,’recall’, ’f-score’), sample_weight=None)\n",
        "\n",
        "it can be : binary,macro,weighted,samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDkxunbkKBI1",
        "outputId": "6139020a-235d-468f-a54b-9c9f1cea8d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# example \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
        "y_true =  np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
        " \n",
        "precision_recall_fscore_support(y_true, y_pred, average=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.66666667, 0.        , 0.        ]),\n",
              " array([1., 0., 0.]),\n",
              " array([0.8, 0. , 0. ]),\n",
              " array([2, 2, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTBwErcfLUNT"
      },
      "source": [
        "### Classification Report\n",
        "\n",
        "وهي تقوم بحساب كلا من : precision , recall , f1score , support  لكل قيمة من القيم , سواء ارقام او نصوص , كما تقوم بإظهار المتوسطات بأنواعها macro , micro , support\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6gJkXrTK0k9",
        "outputId": "2b783313-5032-4e85-fab1-9d71ea68a5da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# example \n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
        "y_true =  np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
        " \n",
        "precision_recall_fscore_support(y_true, y_pred, average=\"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3333333333333333, 0.3333333333333333, 0.3333333333333333, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VisYwbLULihn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}